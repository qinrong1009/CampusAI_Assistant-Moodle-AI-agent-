"""
AI æ¨¡åž‹é›†æˆ
æ”¯æŒå¤šå€‹æ¨¡åž‹:
- Ollama (æœ¬åœ°æ¨¡åž‹ - æŽ¨è–¦! ç„¡éœ€ API å¯†é‘°)
- Qwenã€GPT-4V å’Œ Claude 3 Vision (é›²ç«¯ API)
"""

import logging
import os
import base64
from io import BytesIO
from PIL import Image
import json
from datetime import datetime
import requests

logger = logging.getLogger(__name__)

class AIModel:
    """AI æ¨¡åž‹ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ– AI æ¨¡åž‹"""
        # Ollama ä¼ºæœå™¨ä½å€ (é è¨­æ”¹ç‚ºé ç«¯ PrimeHub URL)
        # è‹¥éœ€æ”¹å›žæœ¬åœ°æˆ–å…¶ä»–éƒ¨ç½²ï¼Œè«‹è¨­å®šç’°å¢ƒè®Šæ•¸ OLLAMA_URL
        self.ollama_url = os.getenv('OLLAMA_URL', 'https://primehub.aic.ncku.edu.tw/console/apps/ollama-0-13-0-i1oyy')
        self.ollama_model = os.getenv('OLLAMA_MODEL', 'llava')  # æŽ¨è–¦ä½¿ç”¨ llava è¦–è¦ºæ¨¡åž‹
        self.ollama_enabled = os.getenv('OLLAMA_ENABLED', 'true').lower() == 'true'
        
        # é›²ç«¯ API é…ç½®
        self.qwen_api_key = os.getenv('QWEN_API_KEY')
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.claude_api_key = os.getenv('CLAUDE_API_KEY')
        
        # åˆå§‹åŒ–å„å€‹æ¨¡åž‹çš„å®¢æˆ¶ç«¯
        self._init_clients()
        
        # æª¢æŸ¥ Ollama é€£æŽ¥
        self._check_ollama_connection()
    
    def _check_ollama_connection(self):
        """æª¢æŸ¥ Ollama æ˜¯å¦å¯ç”¨"""
        try:
            if self.ollama_enabled:
                response = requests.get(f'{self.ollama_url}/api/tags', timeout=2)
                if response.status_code == 200:
                    logger.info(f'âœ… Ollama é€£æŽ¥æˆåŠŸ: {self.ollama_url}')
                    available_models = response.json().get('models', [])
                    logger.info(f'å¯ç”¨æ¨¡åž‹: {[m["name"] for m in available_models]}')
                else:
                    logger.warning(f'âš ï¸ Ollama è¿”å›žéŒ¯èª¤: {response.status_code}')
                    self.ollama_enabled = False
        except Exception as e:
            logger.warning(f'âš ï¸ ç„¡æ³•é€£æŽ¥åˆ° Ollama ({self.ollama_url}): {str(e)}')
            self.ollama_enabled = False
    
    def _init_clients(self):
        """åˆå§‹åŒ– API å®¢æˆ¶ç«¯"""
        try:
            if self.qwen_api_key:
                from dashscope import MultiModalConversation
                self.qwen_client = MultiModalConversation
                logger.info('âœ… Qwen å®¢æˆ¶ç«¯å·²åˆå§‹åŒ–')
            
            if self.openai_api_key:
                import openai
                openai.api_key = self.openai_api_key
                self.openai_client = openai
                logger.info('âœ… OpenAI å®¢æˆ¶ç«¯å·²åˆå§‹åŒ–')
            
            if self.claude_api_key:
                import anthropic
                self.claude_client = anthropic.Anthropic(api_key=self.claude_api_key)
                logger.info('âœ… Claude å®¢æˆ¶ç«¯å·²åˆå§‹åŒ–')
        except Exception as e:
            logger.warning(f'åˆå§‹åŒ– API å®¢æˆ¶ç«¯æ™‚å‡ºç¾è­¦å‘Š: {str(e)}')
    
    def process_query(self, question: str, screenshot: str, model_type: str = 'llava') -> str:
        """
        è™•ç†ä½¿ç”¨è€…æŸ¥è©¢
        
        Args:
            question: ä½¿ç”¨è€…çš„å•é¡Œ
            screenshot: base64 ç·¨ç¢¼çš„æˆªåœ–
            model_type: ä½¿ç”¨çš„æ¨¡åž‹åç¨± (llava/qwen2.5/qwen/gpt/claude)
        
        Returns:
            AI çš„å›žæ‡‰æ–‡æœ¬
        """
        logger.info(f'è™•ç†æŸ¥è©¢ï¼Œæ¨¡åž‹: {model_type}')
        
        try:
            # è§£ç¢¼æˆªåœ–
            image_data = base64.b64decode(screenshot.split(',')[1] if ',' in screenshot else screenshot)
            
            # æ ¹æ“šæ¨¡åž‹é¡žåž‹èª¿ç”¨ç›¸æ‡‰çš„æ–¹æ³•
            if model_type in ['llava', 'llava:34b', 'bakllava', 'qwen2.5', 'qwen:7b', 'qwen:7b-vision', 'qwen2.5vl:7b', 'qwen2.5-vl', 'qwen-vl', 'qwen-vl-chat']:
                # æ‰€æœ‰æœ¬åœ° Ollama æ¨¡åž‹
                return self._query_ollama(question, image_data, model_type)
            elif model_type == 'gpt':
                return self._query_gpt(question, image_data)
            elif model_type == 'claude':
                return self._query_claude(question, image_data)
            else:
                # é»˜èªä½¿ç”¨ Ollama ä¸­çš„ LLaVA
                if self.ollama_enabled:
                    return self._query_ollama(question, image_data, 'llava')
                else:
                    return "ç„¡å¯ç”¨çš„æ¨¡åž‹ï¼Œè«‹æª¢æŸ¥é…ç½®"
                
        except Exception as e:
            logger.error(f'è™•ç†æŸ¥è©¢å¤±æ•—: {str(e)}')
            raise
    
    def _query_ollama(self, question: str, image_data: bytes, model_name: str = None) -> str:
        """
        ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡åž‹å›žæ‡‰ (æŽ¨è–¦!)
        
        æ”¯æŒçš„æ¨¡åž‹:
        - llava - è¦–è¦ºèªžè¨€æ¨¡åž‹ (æŽ¨è–¦ç”¨æ–¼åœ–ç‰‡åˆ†æž)
        - qwen2.5 - Qwen é–‹æºç‰ˆæœ¬ (å¤šåŠŸèƒ½)
        - qwen:7b - Qwen 7B ç‰ˆæœ¬
        - bakllava - è¼•é‡è¦–è¦ºæ¨¡åž‹
        
        ç„¡éœ€ API å¯†é‘°ï¼Œå®Œå…¨æœ¬åœ°é‹è¡Œ!
        """
        try:
            if not self.ollama_enabled:
                return "Ollama æœªé…ç½®æˆ–ç„¡æ³•é€£æŽ¥"
            
            # ä½¿ç”¨æŒ‡å®šçš„æ¨¡åž‹æˆ–é»˜èªæ¨¡åž‹
            model = model_name or self.ollama_model
            
            # ç·¨ç¢¼åœ–ç‰‡ç‚º base64
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # æ§‹å»ºç³»çµ±æç¤º
            system_prompt = """ä½ æ˜¯ä¸€å€‹æ ¡å‹™ç³»çµ±æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ çš„è·è²¬æ˜¯å¹«åŠ©æˆåŠŸå¤§å­¸çš„å¸«ç”Ÿè§£æ±ºæ ¡å‹™ç³»çµ±ç›¸é—œçš„å•é¡Œã€‚

ä½ çš„å›žæ‡‰æ‡‰è©²ï¼š
1. ç°¡æ½”æ˜Žäº†ï¼Œç›´æŽ¥å›žç­”å•é¡Œ
2. åŸºæ–¼æä¾›çš„æˆªåœ–å’Œæ–‡æœ¬å…§å®¹
3. åŒ…å«å…·é«”çš„æ­¥é©ŸæŒ‡å¼•ï¼ˆå¦‚æžœé©ç”¨ï¼‰
4. ç”¨ç¹é«”ä¸­æ–‡å›žæ‡‰
5. å¦‚æžœç„¡æ³•å¾žæˆªåœ–ä¸­ç²å–è¶³å¤ ä¿¡æ¯ï¼Œè«‹èªªæ˜Ž

æ ¡å‹™ç³»çµ±å¸¸è¦‹åŠŸèƒ½ï¼š
- é¸èª²ç³»çµ±
- æˆç¸¾æŸ¥è©¢
- èª²ç¨‹è¡¨æŸ¥è©¢
- æ•™å®¤é ç´„
- ç¹³è²»ç³»çµ±
- å­¸ä½æŸ¥è©¢"""
            
            # èª¿ç”¨ Ollama API
            logger.info(f'èª¿ç”¨ Ollama æ¨¡åž‹: {model} ({self.ollama_url})')
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯è¦–è¦ºæ¨¡åž‹ï¼ˆéœ€è¦åœ–ç‰‡ï¼‰é‚„æ˜¯æ–‡æœ¬æ¨¡åž‹
            is_vision_model = model.lower() in ['llava', 'bakllava', 'qwen:7b-vision', 'qwen2.5vl:7b', 'qwen2.5-vl', 'qwen-vl', 'qwen-vl-chat']
            
            if is_vision_model:
                # è¦–è¦ºæ¨¡åž‹ï¼šç™¼é€åœ–ç‰‡å’Œæ–‡å­—
                response = requests.post(
                    f'{self.ollama_url}/api/generate',
                    json={
                        'model': model,
                        'prompt': f"{system_prompt}\n\nç”¨æˆ¶å•é¡Œ: {question}",
                        'stream': False,
                        'images': [image_base64]  # ç™¼é€ base64 ç·¨ç¢¼çš„åœ–ç‰‡
                    },
                    timeout=120  # çµ¦ AI è¶³å¤ çš„æ™‚é–“æ€è€ƒ
                )
            else:
                # æ–‡æœ¬æ¨¡åž‹ï¼ˆå¦‚ Qwen2.5ï¼‰ï¼šåªç™¼é€æ–‡å­—
                response = requests.post(
                    f'{self.ollama_url}/api/generate',
                    json={
                        'model': model,
                        'prompt': f"{system_prompt}\n\nç”¨æˆ¶å•é¡Œ: {question}",
                        'stream': False
                    },
                    timeout=120  # çµ¦ AI è¶³å¤ çš„æ™‚é–“æ€è€ƒ
                )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get('response', '').strip()
                logger.info('âœ… Ollama å›žæ‡‰æˆåŠŸ')
                return answer if answer else "ç„¡æ³•ç”Ÿæˆå›žæ‡‰ï¼Œè«‹é‡è©¦"
            else:
                logger.error(f'Ollama API éŒ¯èª¤: {response.status_code} - {response.text}')
                return f"Ollama å›žæ‡‰å¤±æ•— ({response.status_code}): {response.text[:200]}"
                
        except requests.exceptions.Timeout:
            logger.error('Ollama è«‹æ±‚è¶…æ™‚')
            return "Ollama è™•ç†è¶…æ™‚ï¼Œè«‹å˜—è©¦æ›´ç°¡å–®çš„åœ–ç‰‡æˆ–å•é¡Œ"
        except requests.exceptions.ConnectionError:
            logger.error(f'ç„¡æ³•é€£æŽ¥åˆ° Ollama: {self.ollama_url}')
            return f"ç„¡æ³•é€£æŽ¥åˆ° Ollama æœå‹™ ({self.ollama_url})\n\nðŸ’¡ æç¤º: ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œ:\n  ollama serve"
        except Exception as e:
            logger.error(f'Ollama æŸ¥è©¢å¤±æ•—: {str(e)}')
            return f"Ollama æŸ¥è©¢å‡ºéŒ¯: {str(e)}"
    
    def _query_qwen(self, question: str, image_data: bytes) -> str:
        """ä½¿ç”¨ Qwen 2.5 æ¨¡åž‹å›žæ‡‰"""
        try:
            if not self.qwen_api_key:
                return "Qwen API å¯†é‘°æœªé…ç½®"
            
            from dashscope import MultiModalConversation
            import base64
            
            # ç·¨ç¢¼åœ–ç‰‡
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # æ§‹å»ºç³»çµ±æç¤º
            system_prompt = """ä½ æ˜¯ä¸€å€‹æ ¡å‹™ç³»çµ±æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ çš„è·è²¬æ˜¯å¹«åŠ©æˆåŠŸå¤§å­¸çš„å¸«ç”Ÿè§£æ±ºæ ¡å‹™ç³»çµ±ç›¸é—œçš„å•é¡Œã€‚
            
ä½ çš„å›žæ‡‰æ‡‰è©²ï¼š
1. ç°¡æ½”æ˜Žäº†ï¼Œç›´æŽ¥å›žç­”å•é¡Œ
2. åŸºæ–¼æä¾›çš„æˆªåœ–å’Œæ–‡æœ¬å…§å®¹
3. åŒ…å«å…·é«”çš„æ­¥é©ŸæŒ‡å¼•ï¼ˆå¦‚æžœé©ç”¨ï¼‰
4. ç”¨ç¹é«”ä¸­æ–‡å›žæ‡‰
5. å¦‚æžœç„¡æ³•å¾žæˆªåœ–ä¸­ç²å–è¶³å¤ ä¿¡æ¯ï¼Œè«‹èªªæ˜Ž

æ ¡å‹™ç³»çµ±å¸¸è¦‹åŠŸèƒ½ï¼š
- é¸èª²ç³»çµ±
- æˆç¸¾æŸ¥è©¢
- èª²ç¨‹è¡¨æŸ¥è©¢
- æ•™å®¤é ç´„
- ç¹³è²»ç³»çµ±
- å­¸ä½æŸ¥è©¢"""
            
            # æº–å‚™æ¶ˆæ¯
            message = {
                'role': 'user',
                'content': [
                    {'type': 'text', 'text': f"ç³»çµ±æˆªåœ–çš„å•é¡Œï¼š{question}"},
                    {'type': 'image', 'image': f'data:image/jpeg;base64,{image_base64}'}
                ]
            }
            
            # èª¿ç”¨ Qwen API
            response = MultiModalConversation.call(
                model='qwen-vl-max',
                messages=[message],
                system=system_prompt
            )
            
            if response.status_code == 200:
                return response.output.choices[0].message.content[0].text
            else:
                logger.error(f'Qwen API éŒ¯èª¤: {response}')
                return f"Qwen å›žæ‡‰å¤±æ•—: {response.message}"
                
        except ImportError:
            logger.error('dashscope æœªå®‰è£')
            return "Qwen SDK æœªå®‰è£ï¼Œè«‹å®‰è£ dashscope"
        except Exception as e:
            logger.error(f'Qwen æŸ¥è©¢å¤±æ•—: {str(e)}')
            return f"Qwen æŸ¥è©¢å‡ºéŒ¯: {str(e)}"
    
    def _query_gpt(self, question: str, image_data: bytes) -> str:
        """ä½¿ç”¨ GPT-4V æ¨¡åž‹å›žæ‡‰"""
        try:
            if not self.openai_api_key:
                return "OpenAI API å¯†é‘°æœªé…ç½®"
            
            import openai
            import base64
            
            # ç·¨ç¢¼åœ–ç‰‡
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            response = openai.ChatCompletion.create(
                model="gpt-4-vision-preview",
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€å€‹æ ¡å‹™ç³»çµ±æ™ºèƒ½åŠ©æ‰‹ã€‚å¹«åŠ©æˆåŠŸå¤§å­¸çš„å¸«ç”Ÿè§£æ±ºæ ¡å‹™ç³»çµ±ç›¸é—œå•é¡Œã€‚
å›žæ‡‰æ‡‰ç°¡æ½”ã€å¯¦ç”¨ï¼ŒåŒ…å«å…·é«”æ­¥é©Ÿï¼ˆå¦‚éœ€è¦ï¼‰ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡å›žæ‡‰ã€‚"""
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": f"æ ¹æ“šé€™å€‹æ ¡å‹™ç³»çµ±æˆªåœ–ï¼Œè«‹å›žç­”ï¼š{question}"},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1024
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f'GPT æŸ¥è©¢å¤±æ•—: {str(e)}')
            return f"GPT æŸ¥è©¢å‡ºéŒ¯: {str(e)}"
    
    def _query_claude(self, question: str, image_data: bytes) -> str:
        """ä½¿ç”¨ Claude 3 Vision æ¨¡åž‹å›žæ‡‰"""
        try:
            if not self.claude_api_key:
                return "Claude API å¯†é‘°æœªé…ç½®"
            
            import base64
            
            # ç·¨ç¢¼åœ–ç‰‡
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            response = self.claude_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1024,
                system="""ä½ æ˜¯ä¸€å€‹æ ¡å‹™ç³»çµ±æ™ºèƒ½åŠ©æ‰‹ã€‚å¹«åŠ©æˆåŠŸå¤§å­¸çš„å¸«ç”Ÿè§£æ±ºæ ¡å‹™ç³»çµ±ç›¸é—œå•é¡Œã€‚
å›žæ‡‰æ‡‰ç°¡æ½”ã€å¯¦ç”¨ï¼ŒåŒ…å«å…·é«”æ­¥é©Ÿï¼ˆå¦‚éœ€è¦ï¼‰ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡å›žæ‡‰ã€‚""",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/jpeg",
                                    "data": image_base64
                                }
                            },
                            {
                                "type": "text",
                                "text": f"æ ¹æ“šé€™å€‹æ ¡å‹™ç³»çµ±æˆªåœ–ï¼Œè«‹å›žç­”ï¼š{question}"
                            }
                        ]
                    }
                ]
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f'Claude æŸ¥è©¢å¤±æ•—: {str(e)}')
            return f"Claude æŸ¥è©¢å‡ºéŒ¯: {str(e)}"
    
    def get_available_models(self) -> dict:
        """ç²å–å¯ç”¨çš„æ¨¡åž‹åˆ—è¡¨"""
        models = {
            'llava': {
                'name': 'ðŸ–¥ï¸ LLaVA (æœ¬åœ° Ollama)',
                'status': 'available' if self.ollama_enabled else 'unconfigured',
                'description': 'è¦–è¦ºæ¨¡åž‹ - é©åˆåœ–ç‰‡åˆ†æž',
                'location': 'local',
                'url': self.ollama_url if self.ollama_enabled else 'æœªé…ç½®'
            },
            'qwen2.5': {
                'name': 'ðŸ–¥ï¸ Qwen 2.5 (æœ¬åœ° Ollama)',
                'status': 'available' if self.ollama_enabled else 'unconfigured',
                'description': 'å¤šåŠŸèƒ½æ¨¡åž‹ - é©åˆæ–‡æœ¬åˆ†æž',
                'location': 'local',
                'url': self.ollama_url if self.ollama_enabled else 'æœªé…ç½®'
            },
            'bakllava': {
                'name': 'ðŸ–¥ï¸ BakLLaVA (æœ¬åœ° Ollama)',
                'status': 'available' if self.ollama_enabled else 'unconfigured',
                'description': 'è¼•é‡è¦–è¦ºæ¨¡åž‹ - å¿«é€ŸæŽ¨ç†',
                'location': 'local',
                'url': self.ollama_url if self.ollama_enabled else 'æœªé…ç½®'
            },
            'gpt': {
                'name': 'â˜ï¸ GPT-4V (é›²ç«¯)',
                'status': 'available' if self.openai_api_key else 'unconfigured',
                'description': 'OpenAI - éœ€è¦ API å¯†é‘°',
                'location': 'cloud'
            },
            'claude': {
                'name': 'â˜ï¸ Claude 3 Vision (é›²ç«¯)',
                'status': 'available' if self.claude_api_key else 'unconfigured',
                'description': 'Anthropic - éœ€è¦ API å¯†é‘°',
                'location': 'cloud'
            }
        }
        return models
    
    @staticmethod
    def validate_image(image_data: bytes) -> bool:
        """é©—è­‰åœ–ç‰‡æ•¸æ“š"""
        try:
            img = Image.open(BytesIO(image_data))
            return True
        except Exception as e:
            logger.error(f'åœ–ç‰‡é©—è­‰å¤±æ•—: {str(e)}')
            return False
