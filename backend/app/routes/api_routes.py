"""
API è·¯ç”±å®šç¾©
"""

from flask import Blueprint, request, jsonify, g
from datetime import datetime
import base64
import logging
import traceback
from ..models.retriever import get_retriever
from ..models import memory_manager
import uuid

bp = Blueprint('api', __name__, url_prefix='/api')
logger = logging.getLogger(__name__)

@bp.route('/ask', methods=['POST'])
def ask_ai():
    """
    ä¸»è¦ç«¯é»ï¼šæ¥æ”¶è¢å¹•æˆªåœ–å’Œå•é¡Œï¼Œè¿”å› AI å›æ‡‰
    
    è«‹æ±‚æ•¸æ“š:
    {
        "question": "ä½¿ç”¨è€…çš„å•é¡Œ",
        "screenshot": "base64 ç·¨ç¢¼çš„åœ–ç‰‡",
        "model": "ai æ¨¡å‹åç¨± (qwen/gpt/claude)",
        "timestamp": "ISO æ ¼å¼æ™‚é–“æˆ³"
    }
    """
    try:
        data = request.get_json()

        # é©—è­‰å¿…éœ€çš„æ¬„ä½
        if not data:
            return jsonify({'error': 'ç„¡æ•ˆçš„è«‹æ±‚é«”'}), 400

        question = data.get('question', '').strip()
        screenshot = data.get('screenshot')
        model = data.get('model', 'llava')
        # session_id: optional. If provided, server will keep short-term memory
        # for this session. If not provided, server will generate one and return
        # it in the response so the client can reuse it for subsequent calls.
        session_id = data.get('session_id')

        if not question:
            return jsonify({'error': 'å•é¡Œä¸èƒ½ç‚ºç©º'}), 400

        if not screenshot:
            return jsonify({'error': 'æˆªåœ–ä¸èƒ½ç‚ºç©º'}), 400
        
        # è¨˜éŒ„è«‹æ±‚
        logger.info(f'æ¥æ”¶å•é¡Œ: {question[:50]}... ä½¿ç”¨æ¨¡å‹: {model}')
        # è¨˜éŒ„æ˜¯å¦æ”¶åˆ°æˆªåœ–èˆ‡ç°¡çŸ­é è¦½ï¼ˆé¿å…åœ¨æ—¥èªŒä¸­æ‰“å‡ºå®Œæ•´ base64ï¼‰
        try:
            if screenshot:
                preview = (screenshot[:80] + '...') if len(screenshot) > 80 else screenshot
                logger.info(f'[api] æ”¶åˆ° screenshot é•·åº¦={len(screenshot)} preview={preview}')
            else:
                logger.info('[api] æœªæ”¶åˆ° screenshot')
        except Exception as e:
            logger.warning(f'[api] ç„¡æ³•è¨˜éŒ„ screenshot è³‡è¨Š: {e}')
        
        # ğŸ¯ ä½¿ç”¨è¼•é‡ç´šæª¢ç´¢å™¨å–å¾—ç›¸é—œçŸ¥è­˜ç‰‡æ®µ
        retriever = get_retriever()
        relevant_chunks = retriever.retrieve(question, max_chunks=2)
        context = "\n\n".join(relevant_chunks) if relevant_chunks else ""

        # ä½¿ç”¨ LangChain ConversationBufferMemory ç®¡ç†çŸ­æœŸæœƒè©±è¨˜æ†¶
        # è‹¥ client æœªå‚³ session_idï¼Œå»ºç«‹ä¸€å€‹ä¸¦å›å‚³çµ¦ client
        if not session_id:
            session_id = str(uuid.uuid4())

        memory = memory_manager.manager.get_memory(session_id)
        # load memory history (string)
        try:
            logger.info(f"[memory] loading memory for session={session_id}")
            mem_vars = memory.load_memory_variables({})
            history = mem_vars.get('history', '') if mem_vars else ''
            logger.info(f"[memory] loaded history length={len(history) if history else 0} for session={session_id}")
        except Exception as me:
            logger.warning(f"[memory] failed to load memory for session={session_id}: {me}")
            mem_vars = {}
            history = ''

        parts = []
        if history:
            parts.append(f"Conversation history:\n{history}")
        if context:
            parts.append(f"Reference materials:\n{context}")
        parts.append(f"User question:\n{question}")

        enhanced_question = "\n\n".join(parts)

        # èª¿ç”¨ AI æ¨¡å‹ï¼ˆä½¿ç”¨å¢å¼·å¾Œçš„å•é¡Œï¼‰
        response_text = g.ai_model.process_query(
            question=enhanced_question,
            screenshot=screenshot,
            model_type=model
        )

        # å°‡æœ¬è¼ªå°è©±å­˜å…¥ memoryï¼ˆuser input + assistant outputï¼‰
        try:
            logger.info(f"[memory] saving conversation for session={session_id} (question_len={len(question)})")
            memory.save_context({"input": question}, {"output": response_text})
            logger.info(f"[memory] saved conversation for session={session_id}")
        except Exception as save_err:
            logger.warning(f'ç„¡æ³•å°‡å°è©±ä¿å­˜è‡³è¨˜æ†¶: {save_err}')
        
        return jsonify({
            'status': 'success',
            'response': response_text,
            'model': model,
            'session_id': session_id,
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        logger.error(f'è™•ç†è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
        logger.error(traceback.format_exc())
        return jsonify({
            'error': 'è™•ç†è«‹æ±‚å¤±æ•—',
            'message': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@bp.route('/analyze', methods=['POST'])
def analyze():
    """
    Chrome æ“´å±•ä½¿ç”¨çš„ç«¯é»ï¼ˆåˆ¥åï¼‰
    èˆ‡ /ask ç›¸åŒçš„åŠŸèƒ½
    """
    return ask_ai()

@bp.route('/models', methods=['GET'])
def get_available_models():
    """ç²å–å¯ç”¨çš„ AI æ¨¡å‹åˆ—è¡¨"""
    try:
        models = g.ai_model.get_available_models()
        return jsonify({
            'status': 'success',
            'models': models,
            'timestamp': datetime.now().isoformat()
        }), 200
    except Exception as e:
        logger.error(f'ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {str(e)}')
        return jsonify({
            'error': 'ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—',
            'timestamp': datetime.now().isoformat()
        }), 500


@bp.route('/set_model', methods=['POST'])
def set_model():
    """åœ¨é‹è¡Œæ™‚è¨­ç½®å…¨å±€é è¨­æ¨¡å‹ï¼ˆæœƒæ›´æ–° server-side çš„ default modelï¼‰ã€‚"""
    try:
        data = request.get_json() or {}
        model = data.get('model')
        if not model:
            return jsonify({'error': 'model required'}), 400

        # é©—è­‰æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨æ¸…å–®ä¸­
        available = g.ai_model.get_available_models()
        if model not in available:
            return jsonify({'error': 'model not recognized', 'available': list(available.keys())}), 400

        # è¨­ç½®å…¨å±€é è¨­æ¨¡å‹
        g.ai_model.ollama_model = model
        logger.info(f'å…¨å±€é è¨­æ¨¡å‹å·²æ›´æ–°ç‚º: {model}')
        return jsonify({'status': 'success', 'model': model}), 200
    except Exception as e:
        logger.error(f'è¨­ç½®æ¨¡å‹å¤±æ•—: {e}')
        return jsonify({'error': 'è¨­ç½®æ¨¡å‹å¤±æ•—'}), 500

@bp.route('/test', methods=['GET'])
def test_endpoint():
    """æ¸¬è©¦ç«¯é»"""
    return jsonify({
        'status': 'success',
        'message': 'æ ¡å‹™ç³»çµ± AI åŠ©æ‰‹å¾Œç«¯æ­£åœ¨é‹è¡Œ',
        'timestamp': datetime.now().isoformat()
    }), 200


@bp.route('/clear_memory', methods=['POST'])
def clear_memory():
    """æ¸…é™¤æŒ‡å®š session çš„çŸ­æœŸè¨˜æ†¶ï¼ˆè‹¥æä¾›ï¼‰ã€‚"""
    try:
        data = request.get_json() or {}
        session_id = data.get('session_id')
        if not session_id:
            return jsonify({'error': 'session_id required'}), 400

        logger.info(f"[memory] clear_memory request for session={session_id}")
        removed = memory_manager.manager.clear_memory(session_id)
        logger.info(f"[memory] clear_memory result for session={session_id} removed={removed}")
        return jsonify({'status': 'success', 'removed': removed}), 200
    except Exception as e:
        logger.error(f'æ¸…é™¤è¨˜æ†¶å¤±æ•—: {e}')
        return jsonify({'error': 'æ¸…é™¤è¨˜æ†¶å¤±æ•—'}), 500
