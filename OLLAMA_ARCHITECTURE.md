# Ollama 集成架構圖

## 系統架構概覽

```
┌─────────────────────────────────────────────────────────────────┐
│                        用戶瀏覽器                                 │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │                    Chrome 瀏覽器                          │   │
│  │  ┌────────────────────────────────────────────────────┐  │   │
│  │  │            Chrome Web Extension                  │  │   │
│  │  │  ┌──────────────────────────────────────────────┐ │  │   │
│  │  │  │  popup.html (設定面板)                      │ │  │   │
│  │  │  │  - 模型選擇: Ollama/Qwen/GPT-4V/Claude    │ │  │   │
│  │  │  │  - API 配置                                │ │  │   │
│  │  │  └──────────────────────────────────────────────┘ │  │   │
│  │  │  ┌──────────────────────────────────────────────┐ │  │   │
│  │  │  │  sidebar.html (主介面)                      │ │  │   │
│  │  │  │  - 截圖按鈕 (html2canvas)                 │ │  │   │
│  │  │  │  - 問題輸入框                              │ │  │   │
│  │  │  │  - AI 回應顯示                             │ │  │   │
│  │  │  └──────────────────────────────────────────────┘ │  │   │
│  │  └────────────────────────────────────────────────────┘  │   │
│  │           ↓ 發送請求 (base64 截圖 + 問題)              │   │
│  └──────────────────────────────────────────────────────────┘   │
└─────────────────┬───────────────────────────────────────────────┘
                  │ HTTP POST /api/ask
                  │
        ┌─────────▼─────────┐
        │  後端 Flask 服務   │
        │  (localhost:5000) │
        └─────────┬─────────┘
                  │
        ┌─────────▼──────────────────────────────────────┐
        │   api_routes.py (路由層)                      │
        │   ┌────────────────────────────────────────┐  │
        │   │  /api/ask                             │  │
        │   │  - 解碼 base64 截圖                   │  │
        │   │  - 獲取模型類型                       │  │
        │   │  - 調用 AIModel.process_query()       │  │
        │   └────────────────────────────────────────┘  │
        └─────────┬──────────────────────────────────────┘
                  │
        ┌─────────▼──────────────────────────────────────┐
        │   AIModel (app/models/ai_model.py)            │
        │   ┌────────────────────────────────────────┐  │
        │   │  process_query()                       │  │
        │   │  - 根據 model_type 選擇處理方式      │  │
        │   │  - 支持多模型路由                     │  │
        │   └────────────────────────────────────────┘  │
        │                    │                          │
        │      ┌─────────────┼─────────────┐            │
        │      │             │             │            │
        ▼      ▼             ▼             ▼            ▼
     ┌─────┐ ┌─────┐ ┌──────┐ ┌──────┐ ┌──────┐
     │Qwen │ │ GPT │ │Claude│ │Ollama│ │...   │
     │2.5  │ │4-V  │ │3     │ │      │ │Models│
     └──┬──┘ └──┬──┘ └───┬──┘ └───┬──┘ └──────┘
        │       │        │        │
        │       │        │        └──────────────┐
        │       │        │                       │
        ▼       ▼        ▼                       ▼
     ┌──────────────────────────┐       ┌──────────────────────┐
     │    OpenAI API            │       │   Ollama Local       │
     │    (需要 API 密鑰)       │       │   (無需密鑰)         │
     │    - Qwen 服務           │       │   localhost:11434    │
     │    - OpenAI 服務         │       │                      │
     │    - Anthropic 服務      │       │  ┌────────────────┐  │
     └──────────────────────────┘       │  │ llava 模型     │  │
                                         │  │ llava:34b      │  │
                                         │  │ bakllava       │  │
                                         │  └────────────────┘  │
                                         └──────────────────────┘
```

---

## 請求流程圖

```
用戶在網頁上提問
       │
       ▼
  ┌─────────────────┐
  │  用戶按 Alt+A   │
  │ 或點擊擴展圖標  │
  └────────┬────────┘
           │
           ▼
  ┌─────────────────────────────┐
  │  側邊欄彈出 (sidebar.html)  │
  └────────┬────────────────────┘
           │
           ▼
  ┌─────────────────────────────┐
  │  用戶點擊「📸 截圖」       │
  │  (html2canvas 捕捉頁面)     │
  └────────┬────────────────────┘
           │
           ▼
  ┌──────────────────────────────────────┐
  │  用戶輸入問題並點擊「發送」          │
  │  模型選擇: Ollama/Qwen/GPT-4V/Claude │
  └────────┬─────────────────────────────┘
           │
           ▼
  ┌───────────────────────────────────────────┐
  │  background.js 準備請求                  │
  │  - 檢查 API URL (localStorage)           │
  │  - 檢查模型選擇                          │
  │  - Base64 編碼截圖                      │
  │  - 設置請求頭                            │
  └────────┬────────────────────────────────┘
           │
           ▼ HTTP POST
  ┌─────────────────────────────────────────┐
  │  POST http://localhost:5000/api/ask      │
  │  {                                       │
  │    "question": "...",                    │
  │    "image": "data:image/png;base64,...", │
  │    "model_type": "ollama"                │
  │  }                                       │
  └────────┬────────────────────────────────┘
           │
           ▼
  ┌──────────────────────────────┐
  │  api_routes.py 處理請求     │
  │  - 驗證請求                  │
  │  - 解碼 base64 圖片         │
  │  - 調用 AIModel             │
  └────────┬─────────────────────┘
           │
           ▼
  ┌────────────────────────────────────┐
  │  AIModel.process_query()           │
  │  模型路由決策樹:                   │
  │  ├─ "ollama" 選擇?                │
  │  │  └─ Ollama 可用?               │
  │  │     ├─ 是 → _query_ollama()   │
  │  │     └─ 否 → _query_qwen()     │
  │  ├─ "qwen" → _query_qwen()        │
  │  ├─ "gpt" → _query_gpt()          │
  │  ├─ "claude" → _query_claude()    │
  │  └─ 未指定 → 智能選擇             │
  └────────┬────────────────────────────┘
           │
  ┌────────┴────────┬─────────┬──────────┬──────────┐
  │                 │         │          │          │
  ▼                 ▼         ▼          ▼          ▼
 Ollama          Qwen 2.5   GPT-4V    Claude      其他
 本地推理        阿里雲      OpenAI    Anthropic   模型
 
┌──────────────────────────────┐
│ 本地 Ollama 處理流程:         │
│ 1. Base64 解碼圖片          │
│ 2. 編碼為 Base64            │
│ 3. POST 到 localhost:11434  │
│ 4. 等待模型推理 (2-10 秒)  │
│ 5. 解析 JSON 回應           │
│ 6. 返回 AI 文本             │
└──────────────────────────────┘
           │
           ▼
  ┌──────────────────────────────┐
  │  返回 JSON 回應              │
  │  {                           │
  │    "response": "AI 回答...", │
  │    "model": "ollama",        │
  │    "timestamp": "..."        │
  │  }                           │
  └────────┬─────────────────────┘
           │
           ▼
  ┌──────────────────────────────┐
  │  sidebar.js 顯示回應         │
  │  - 隱藏加載動畫             │
  │  - 顯示 AI 文本             │
  │  - 支持清除/重試            │
  └────────┬─────────────────────┘
           │
           ▼
  ┌──────────────────────────────┐
  │  用戶看到 AI 回答在側邊欄   │
  │  解決校務系統問題          │
  └──────────────────────────────┘
```

---

## AI 模型決策樹

```
用戶選擇模型
    │
    ├─ "ollama"
    │  ├─ Ollama 已配置? ✓
    │  ├─ Ollama 服務運行? ✓
    │  ├─ 視覺模型已安裝? (llava)
    │  └─ ✅ 使用 _query_ollama()
    │     └─ 如果超時或連接失敗
    │        ├─ 記錄錯誤
    │        ├─ Qwen 已配置?
    │        │  └─ 使用 _query_qwen()
    │        └─ 返回友好的錯誤提示
    │
    ├─ "qwen"
    │  ├─ Qwen API 密鑰已配置? ✓
    │  └─ ✅ 使用 _query_qwen()
    │
    ├─ "gpt"
    │  ├─ OpenAI API 密鑰已配置? ✓
    │  └─ ✅ 使用 _query_gpt()
    │
    ├─ "claude"
    │  ├─ Claude API 密鑰已配置? ✓
    │  └─ ✅ 使用 _query_claude()
    │
    └─ 預設/未指定
       ├─ Ollama 可用? → 使用 Ollama
       ├─ Qwen 可用?  → 使用 Qwen
       ├─ GPT 可用?   → 使用 GPT
       ├─ Claude 可用? → 使用 Claude
       └─ 都不可用?   → 返回錯誤
```

---

## 數據流向圖

```
┌──────────────────────────────────────────────────────────────┐
│                    前端 (Chrome 擴展)                        │
│                                                              │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 用戶數據                                            │   │
│  │ ├─ 頁面截圖 (PNG → Base64)                        │   │
│  │ └─ 用戶問題 (文本)                                │   │
│  └──────────────┬──────────────────────────────────────┘   │
└─────────────────┼──────────────────────────────────────────┘
                  │ (加密 HTTPS/本地)
                  ▼
         ┌────────────────────┐
         │  Flask 後端        │
         │  (localhost:5000)  │
         └────────┬───────────┘
                  │
      ┌───────────┼───────────┐
      │           │           │
      ▼           ▼           ▼
  ┌────────┐ ┌────────┐  ┌──────────────┐
  │請求解析│ │圖片處理│  │模型路由決策  │
  │驗證    │ │Base64  │  │選擇處理方法  │
  │        │ │驗證    │  │              │
  └────────┘ └────────┘  └──────────────┘
      │           │           │
      └───────────┼───────────┘
                  │
      ┌───────────▼───────────┐
      │  AIModel.process()    │
      └───────────┬───────────┘
                  │
    ┌─────────────┼──────────────┐
    │             │              │
    ▼             ▼              ▼
┌─────────┐  ┌─────────┐   ┌──────────────┐
│ Ollama  │  │ 雲端 API│   │其他模型      │
│本地推理 │  │遠程調用 │   │備選方案      │
└────┬────┘  └────┬────┘   └───┬─────────┘
     │            │            │
     │            │            │
     └────────────┼────────────┘
                  │
                  ▼
         ┌────────────────────┐
         │  AI 生成回答       │
         │  (文本回應)        │
         └────────┬───────────┘
                  │
                  ▼ JSON 回應
         ┌────────────────────┐
         │  API 返回結果      │
         │  {                 │
         │   "response": "..." │
         │   "model": "..."    │
         │   "timestamp": "..."│
         │  }                  │
         └────────┬───────────┘
                  │
                  ▼ (加密 HTTPS/本地)
    ┌─────────────────────────────────┐
    │  前端 (Chrome 擴展)             │
    │  ├─ 顯示 AI 回答               │
    │  ├─ 支持複製                    │
    │  ├─ 支持清除                    │
    │  └─ 支持重新提問               │
    └─────────────────────────────────┘
```

---

## Ollama 本地推理流程

```
用戶請求 (model_type = "ollama")
    │
    ▼
┌─────────────────────────────────────┐
│ 1. 驗證 Ollama 配置                │
│    OLLAMA_ENABLED = true ✓         │
│    OLLAMA_URL = localhost:11434 ✓  │
│    OLLAMA_MODEL = llava ✓          │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 2. 解碼圖片數據                     │
│    Base64 → 二進制 PNG              │
│    驗證圖片格式                     │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 3. 編碼為 Base64 (Ollama 格式)     │
│    二進制 → Base64 字符串           │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 4. 構建 Ollama API 請求            │
│    POST /api/generate               │
│    {                                │
│      "model": "llava",              │
│      "prompt": "系統提示 + 問題",  │
│      "stream": false,               │
│      "images": ["base64_string"]    │
│    }                                │
│    超時: 120 秒                      │
└─────────────────────────────────────┘
    │
    ▼ HTTP POST 到本地 Ollama
┌──────────────────────────────────────┐
│ Ollama 服務 (localhost:11434)       │
│  ├─ 接收請求                        │
│  ├─ 加載 llava 模型                │
│  ├─ 處理圖片和問題                 │
│  ├─ 運行 Vision + Language 推理    │
│  └─ 生成回答                        │
└──────────────────────────────────────┘
    │
    ▼ JSON 回應
┌─────────────────────────────────────┐
│ 5. 解析 Ollama 回應                │
│    {                                │
│      "response": "AI 回答...",     │
│      "done": true,                  │
│      "total_duration": 5000000000   │
│    }                                │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 6. 錯誤處理                         │
│    ├─ 超時 → 返回超時提示         │
│    ├─ 連接失敗 → 回退到雲端 API   │
│    ├─ 模型不存在 → 返回明確錯誤   │
│    └─ 其他 → 捕捉並記錄           │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 7. 返回結果給前端                   │
│    "AI 回答..."                    │
│    (或錯誤提示)                    │
└─────────────────────────────────────┘
```

---

## 模型可用性檢查

```
系統啟動
    │
    ▼
┌──────────────────────────────────────────────┐
│ AIModel.__init__()                           │
│  1. 加載環境變數                             │
│     ├─ OLLAMA_ENABLED=true                  │
│     ├─ OLLAMA_URL=localhost:11434           │
│     ├─ OLLAMA_MODEL=llava                   │
│     ├─ QWEN_API_KEY=...                     │
│     ├─ OPENAI_API_KEY=...                   │
│     └─ CLAUDE_API_KEY=...                   │
│                                              │
│  2. 初始化雲端客戶端                         │
│     ├─ Qwen → dashscope SDK ✓              │
│     ├─ OpenAI → openai SDK ✓               │
│     └─ Claude → anthropic SDK ✓            │
│                                              │
│  3. 檢查 Ollama 連接                        │
│     └─ _check_ollama_connection()            │
└──────────────────────────────────────────────┘
    │
    ▼
┌──────────────────────────────────────────────┐
│ _check_ollama_connection()                   │
│  1. 發送 GET 到 Ollama                      │
│     GET http://localhost:11434/api/tags     │
│     超時: 2 秒                               │
│                                              │
│  2. 檢查響應                                 │
│     ├─ 連接成功 + 200 OK                   │
│     │  └─ 解析模型列表                      │
│     │     └─ ollama_enabled = true ✓       │
│     └─ 連接失敗/超時/錯誤                   │
│        └─ ollama_enabled = false            │
│           └─ 記錄警告並繼續                 │
│                                              │
│  3. 記錄結果                                 │
│     ├─ ✅ Ollama 連接成功                  │
│     ├─ 可用模型: [llava:latest, ...]       │
│     └─ 日誌: INFO                           │
└──────────────────────────────────────────────┘
    │
    ▼
┌──────────────────────────────────────────────┐
│ get_available_models() 查詢                  │
│  返回所有模型的狀態:                         │
│  {                                           │
│    "ollama": {                              │
│      "name": "Ollama (本地)",               │
│      "status": "available",                 │
│      "model": "llava"                       │
│    },                                        │
│    "qwen": {                                │
│      "name": "Qwen 2.5",                    │
│      "status": "available" | "unconfigured" │
│    },                                        │
│    "gpt": { ... },                          │
│    "claude": { ... }                        │
│  }                                           │
└──────────────────────────────────────────────┘
```

---

## 文件結構關係

```
├── 前端
│   └── chrome-extension/
│       ├── manifest.json (擴展配置)
│       └── src/
│           ├── html/
│           │   ├── popup.html (模型選擇 UI) ← 更新
│           │   └── sidebar.html (交互界面)
│           ├── css/
│           │   ├── popup.css
│           │   └── sidebar.css
│           └── js/
│               ├── background.js (API 通信)
│               ├── popup.js (設定邏輯)
│               ├── sidebar.js (主邏輯)
│               └── content.js (注入腳本)
│
├── 後端
│   └── backend/
│       ├── .env.example (Ollama 配置) ← 更新
│       ├── requirements.txt (依賴)
│       ├── app.py (主應用)
│       ├── config.py
│       ├── wsgi.py
│       └── app/
│           ├── __init__.py
│           ├── models/
│           │   ├── ai_model.py (Ollama 集成) ← 核心更新
│           │   └── data_models.py
│           └── routes/
│               └── api_routes.py
│
├── 文檔
│   ├── README.md (更新)
│   ├── QUICKSTART.md (更新)
│   ├── SETUP.md (更新)
│   ├── USAGE.md (更新)
│   ├── OLLAMA_SETUP.md (新增)
│   ├── OLLAMA_INTEGRATION_SUMMARY.md (新增)
│   ├── OLLAMA_DEPLOYMENT_CHECKLIST.md (新增)
│   └── OLLAMA_COMPLETION_REPORT.md (新增)
│
├── 工具
│   └── test_ollama_integration.py (新增)
│
└── 配置
    ├── docker-compose.yml
    ├── Dockerfile
    └── 啟動腳本
        ├── run_dev.py
        ├── run_dev.sh
        └── run_dev.bat
```

---

## 配置優先級

```
環境變數配置優先級:
1. 命令行參數 (最高)
2. 系統環境變數 (OLLAMA_URL, OLLAMA_MODEL, etc)
3. .env 文件
4. 默認值 (最低)

示例:
export OLLAMA_URL="http://192.168.1.100:11434"  # 環境變數 → 優先
python app.py  # 或從 .env 讀取

API 密鑰優先級:
1. 環境變數 (推薦)
2. .env 文件
3. 密鑰管理器 (未來擴展)
```

---

**這個架構圖展示了 Ollama 集成如何完美地融入現有系統！** 🎉
