#!/usr/bin/env python3
"""
Ollama é›†æˆæ¸¬è©¦è…³æœ¬
é©—è­‰ Ollama æ˜¯å¦æ­£ç¢ºå®‰è£å’Œé…ç½®
"""

import requests
import json
import sys
import base64
from pathlib import Path

def check_ollama_service():
    """æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦é‹è¡Œ"""
    print("ğŸ” æª¢æŸ¥ Ollama æœå‹™...")
    
    ollama_url = "https://primehub.aic.ncku.edu.tw/console/apps/ollama-0-13-0-i1oyy"
    
    try:
        response = requests.get(f"{ollama_url}/api/tags", timeout=5)
        if response.status_code == 200:
            print(f"âœ… Ollama æœå‹™é‹è¡Œæ­£å¸¸: {ollama_url}")
            models = response.json().get("models", [])
            if models:
                print(f"ğŸ“¦ å¯ç”¨æ¨¡å‹:")
                for model in models:
                    print(f"   - {model['name']} ({model['size'] / 1e9:.1f}GB)")
                return True
            else:
                print("âš ï¸ æœªæ‰¾åˆ°å·²å®‰è£çš„æ¨¡å‹")
                return False
        else:
            print(f"âŒ Ollama è¿”å›éŒ¯èª¤: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"âŒ ç„¡æ³•é€£æ¥åˆ° Ollama ({ollama_url})")
        print("ğŸ’¡ æç¤º: è«‹å…ˆé‹è¡Œ `ollama serve`")
        return False
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {str(e)}")
        return False

def check_vision_models():
    """æª¢æŸ¥æ˜¯å¦å®‰è£äº†è¦–è¦ºæ¨¡å‹"""
    print("\nğŸ” æª¢æŸ¥è¦–è¦ºæ¨¡å‹...")
    
    ollama_url = "https://primehub.aic.ncku.edu.tw/console/apps/ollama-0-13-0-i1oyy"
    
    try:
        response = requests.get(f"{ollama_url}/api/tags", timeout=5)
        models = response.json().get("models", [])
        model_names = [m["name"] for m in models]
        
        vision_models = {
            "llava": "æ¨™æº–ç‰ˆ (æ¨è–¦)",
            "llava:34b": "é«˜ç²¾åº¦ç‰ˆ",
            "bakllava": "è¼•é‡ç‰ˆ"
        }
        
        found_vision = False
        for model_name, desc in vision_models.items():
            if any(model_name in name for name in model_names):
                print(f"âœ… å·²å®‰è£: {model_name} ({desc})")
                found_vision = True
        
        if not found_vision:
            print("âš ï¸ æœªæ‰¾åˆ°è¦–è¦ºæ¨¡å‹ï¼Œè«‹é‹è¡Œ:")
            print("   ollama pull llava")
            return False
        
        return True
    except Exception as e:
        print(f"âŒ æª¢æŸ¥å¤±æ•—: {str(e)}")
        return False

def test_generation():
    """æ¸¬è©¦ API èª¿ç”¨"""
    print("\nğŸ§ª æ¸¬è©¦ API èª¿ç”¨...")
    
    ollama_url = "https://primehub.aic.ncku.edu.tw/console/apps/ollama-0-13-0-i1oyy"
    
    try:
        # ç°¡å–®æ–‡æœ¬ç”Ÿæˆæ¸¬è©¦
        response = requests.post(
            f"{ollama_url}/api/generate",
            json={
                "model": "llava",
                "prompt": "ç°¡æ½”å›ç­”: é€™æ˜¯ä»€éº¼ï¼Ÿ",
                "stream": False
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… API èª¿ç”¨æˆåŠŸ")
            return True
        else:
            print(f"âŒ API è¿”å›éŒ¯èª¤: {response.status_code}")
            return False
    except requests.exceptions.Timeout:
        print("â±ï¸ è«‹æ±‚è¶…æ™‚ï¼ˆå¯èƒ½æ¨¡å‹å¤ªå¤§æˆ– GPU ä¸è¶³ï¼‰")
        return False
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False

def check_backend_integration():
    """æª¢æŸ¥å¾Œç«¯é›†æˆ"""
    print("\nğŸ”— æª¢æŸ¥å¾Œç«¯é›†æˆ...")
    
    backend_url = "http://localhost:5000"
    
    try:
        # æª¢æŸ¥å¾Œç«¯æ˜¯å¦é‹è¡Œ
        response = requests.get(f"{backend_url}/health", timeout=5)
        if response.status_code != 200:
            print(f"âš ï¸ å¾Œç«¯æœå‹™æœªå•Ÿå‹•æˆ–è¿”å›éŒ¯èª¤")
            return False
        
        print("âœ… å¾Œç«¯æœå‹™é‹è¡Œæ­£å¸¸")
        
        # æª¢æŸ¥å¯ç”¨æ¨¡å‹
        response = requests.get(f"{backend_url}/api/models", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", {})
            ollama_status = models.get("ollama", {}).get("status")
            if ollama_status == "available":
                print("âœ… Ollama å·²åœ¨å¾Œç«¯é…ç½®ä¸¦å¯ç”¨")
                return True
            else:
                print(f"âš ï¸ Ollama ç‹€æ…‹: {ollama_status}")
                return False
        else:
            print("âŒ ç„¡æ³•ç²å–æ¨¡å‹åˆ—è¡¨")
            return False
            
    except requests.exceptions.ConnectionError:
        print(f"âš ï¸ ç„¡æ³•é€£æ¥åˆ°å¾Œç«¯ ({backend_url})")
        print("ğŸ’¡ æç¤º: è«‹å…ˆé‹è¡Œ `python run_dev.py` æˆ– `python app.py`")
        return False
    except Exception as e:
        print(f"âŒ æª¢æŸ¥å¤±æ•—: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 50)
    print("  Ollama é›†æˆé©—è­‰å·¥å…·")
    print("=" * 50)
    
    results = {
        "Ollama æœå‹™": check_ollama_service(),
        "è¦–è¦ºæ¨¡å‹": check_vision_models(),
        "API èª¿ç”¨": test_generation(),
        "å¾Œç«¯é›†æˆ": check_backend_integration(),
    }
    
    print("\n" + "=" * 50)
    print("  æª¢æŸ¥çµæœ")
    print("=" * 50)
    
    for check, result in results.items():
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"{check}: {status}")
    
    # ç¸½é«”çµæœ
    all_passed = all(results.values())
    
    print("\n" + "=" * 50)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æª¢æŸ¥é€šéï¼Ollama å·²æº–å‚™å°±ç·’")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. å•Ÿå‹•å¾Œç«¯: python run_dev.py")
        print("2. åœ¨ Chrome ä¸­åŠ è¼‰æ“´å±•")
        print("3. åœ¨ç¶²é ä¸ŠæŒ‰ Alt+A æ¸¬è©¦")
    else:
        print("âš ï¸ æŸäº›æª¢æŸ¥å¤±æ•—ï¼Œè«‹æŒ‰ç…§æç¤ºä¿®å¾©")
        print("\nå¸¸è¦‹å•é¡Œ:")
        print("- Ollama æœªé‹è¡Œ: åŸ·è¡Œ `ollama serve`")
        print("- ç¼ºå°‘è¦–è¦ºæ¨¡å‹: åŸ·è¡Œ `ollama pull llava`")
        print("- å¾Œç«¯æœªé‹è¡Œ: åŸ·è¡Œ `python run_dev.py`")
    print("=" * 50)
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    sys.exit(main())
